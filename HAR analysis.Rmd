---
title: "Predictive Modeling of Human Activity Recognition (HAR)"
author: "Coursera Practical Machine Learning Class"
date: "Sunday, August 24, 2014"
output: html_document
---

This assignment was to build a predictive model based upon data generated by wearable accelerometers.  In this study, they monitored 6 different people performing a weight lifting exercise (dumbbell bicep curls) correctly along with four incorrect ways for a total of 5 responses denoted by the value A,B,C,D, and E.  Further details about the study can be found [here](http://groupware.les.inf.puc-rio.br/har) under the heading Weight Lifting Exercises Dataset.

The data provided for this project can be found here:  
Training data - [pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)  
Testing data  - [pml-testing.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)  

After downloading the data and setting the working directory,these data sets required a lot of data cleaning before even beginning the modeling process.  In the initial loading of the data, there were many observations that were empty ("") or contained "#DIV/0!".  These values wreak havoc by converting a numerical class variable to factor class variable.  This becomes problematic when attempting to generate the model which requires numeric values only.  Also present in the data, were variable names with special characters and many variables that were missing more than 97% of the observations.  Here is the process I used for reading and cleaning the data:
```{r,cache=TRUE}
setwd("C:/Users/Crusher/Documents/Coursera/Practical Machine Learning/Project")
# Reading the data utilizing the na.strings feature
trainpml<-read.table("pml-training.csv",sep=",",header=TRUE,na.strings=c("NA","","#DIV/0!"))
testpml<-read.table("pml-testing.csv",sep=",",header=TRUE,na.strings=c("NA","","#DIV/0!"))

# Remove variables missing more than 97% of the observations
trainpmla<-trainpml[,colSums(is.na(trainpml))==0]
# Do the same for test data
testpmla<-testpml[,names(testpml)%in%names(trainpmla)]
testpmla<-cbind(testpmla,testpml[,"problem_id"])
# Rename final column in the test data set
names(testpmla)[60]<-"problem_id"
# Cleanup the special characters in column names
colnames(trainpmla) <- gsub("\\_", "", colnames(trainpmla))
colnames(trainpmla) <- gsub("\\.", "", colnames(trainpmla))
colnames(testpmla) <- gsub("\\_", "", colnames(testpmla))
colnames(testpmla) <- gsub("\\.", "", colnames(testpmla))
```
The pml-testing.csv file contains only 20 observations used for generating the final predicted value (A,B,C,D,E) for each observation to be submitted in the project submission phase.  Therefore, the next step is to subset the pml-training.csv into it's own training and testing set which will be used to build the model before validating on the pml-testing.csv.
```{r,warning=FALSE,message=FALSE,cache=TRUE}
library(caret)
set.seed(333)
intrain<-createDataPartition(y=trainpmla$classe,p=.75,list=FALSE)
subtrainpml<-trainpmla[intrain,]
subtestpml<-trainpmla[-intrain,]
```
Once the data was partitioned, I began to investigate how to reduce the remaining 59 predictor variables by looking at near zero variance, high correlation, and principal components analysis. Then built various models using different methods (train() with methods"rpart" and "rf" and randomForest()) with accuracy ranging from 37% to 99%.  I also experienced many lengthy model building issues, one model took 12+ hours to generate.  I was able to find great insight into decreasing model building times from the class forums.

The following is my final model with the best accuracy.  It uses the train() function with random forest methodology and 4 fold cross validation on 52 predictors (the first seven predictors were removed from analysis since they were non numeric or not measurement data).
```{r,warning=FALSE,message=FALSE,cache=TRUE}
model<-train(subtrainpml$classe~., method="rf",
                 trControl=trainControl(method = "cv", number = 4, allowParallel = TRUE,verboseIter = TRUE),
                 data=subtrainpml[,-c(1:7,60)])
model
CM<-confusionMatrix(subtestpml$classe,predict(model,subtestpml[,-c(1:7,60)]))
CM
```
Printing the model shows the cross validation process and the tuning parameter selection process.

Generating a confusion matrix shows the misclassified predictions and an accuracy rate of .995.  Therefore, the out of sample error rate would be (1-accuracy rate) `r 1-CM$overall[1]` or `r (1-CM$overall[1])*100`%.
